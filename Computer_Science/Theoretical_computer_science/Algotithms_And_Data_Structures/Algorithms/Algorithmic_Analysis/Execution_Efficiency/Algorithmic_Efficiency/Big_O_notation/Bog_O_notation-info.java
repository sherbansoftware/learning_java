package Computer_Science.Theoretical_computer_science.Algotithms_And_Data_Structures.Algorithms.Algorithmic_Analysis.Execution_Efficiency.Algorithmic_Efficiency.Big_O_notation;
// https://en.wikipedia.org/wiki/Big_O_notation

/*
                                                     Big O notation

    Is a mathematical notation:-----------------------------------------------------------------------------------------
        that describes the limiting behavior of a function when the argument tends towards a particular value or infinity.
        Big O is a member of a family of notations invented by Paul Bachmann, Edmund Landau, and others, collectively
        called Bachmannï¿½Landau notation or asymptotic notation.

    In computer science, big O notation is used to classify algorithms ------------------------------------------------
        according to:
            how their run time or space requirements grow -------------------------------------------------------------
            as the input size grows.
        In analytic number theory, big O notation is often used to express a bound on the difference between an arithmetical
        function and a better understood approximation; a famous example of such a difference is the remainder term in
        the prime number theorem.
        Big O notation is also used in many other fields to provide similar estimates.

    Big O notation characterizes functions according to their growth rates:
        different functions with the same growth rate may be represented using the same O notation.
        The letter O is used because the growth rate of a function is also referred to as the order of the function.
        ATest.A description of a function in terms of big O notation usually only provides an upper bound on the growth rate
        of the function. Associated with big O notation are several related notations, using the symbols o, ?, ?, and ?,
        to describe other kinds of bounds on asymptotic growth rates.



*/